{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Google Colab | GitHub |\n",
    "| :---: | :---: |\n",
    "| <a target=\"_blank\" href=\"https://colab.research.google.com/github/sadrasabouri/pyrandwalk/blob/master/Document/Examples.ipynb\"><img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" height=\"50px\" weight=\"50px\" /><br>Run in Google Colab</a> | <a target=\"_blank\" href=\"https://github.com/sadrasabouri/pyrandwalk/blob/master/Document/Examples.ipynb\"><img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"50px\" weight=\"50px\" style=\"padding-bottom:5px;\"/><br>View Source on GitHub</a> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyrandwalk Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version : 1.1\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example set contains bellow examples from the first reference (Introduction to Stochastic Processes):\n",
    "<ul>\n",
    "    <ol>\n",
    "        <li><a href=\"#Finite_Markov_Chains\">Finite_Markov_Chains</a></li>\n",
    "        <ul>\n",
    "            <li><a href=\"#Exercise1_2\">#Exercise1_2</a></li>\n",
    "            <li><a href=\"#Exercise1_3\">#Exercise1_3</a></li>\n",
    "            <li><a href=\"#Exercise1_4\">#Exercise1_4</a></li>\n",
    "            <li><a href=\"#Exercise1_5\">#Exercise1_5</a></li>\n",
    "            <li><a href=\"#Exercise1_8\">#Exercise1_8</a></li>\n",
    "        </ul>\n",
    "        <li><a href=\"#\">Countable_Markov_Chains</a></li>\n",
    "        <li><a href=\"#\">Continous_Time_Markov_Chains</a></li>\n",
    "        <li><a href=\"#Optimal_Stopping\">Optimal_Stopping</a></li>\n",
    "        <ul>\n",
    "            <li><a href=\"#Exercise4_1\">#Exercise4_1</a></li>\n",
    "        </ul>\n",
    "    </ol>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n  from cryptography.utils import int_from_bytes\n/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n  from cryptography.utils import int_from_bytes\n"
    }
   ],
   "source": [
    "!pip -q -q install pyrandwalk\n",
    "from pyrandwalk import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Finite_Markov_Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise1_2\n",
    "\n",
    "Consider a Markov chain with state space \\{0, 1\\} and transition matrix\n",
    "\n",
    "$$\n",
    "P =\n",
    "\\left(\\begin{array}{cc} \n",
    "1/3 & 2/3\\\\\n",
    "3/4 & 1/4\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [0, 1]\n",
    "trans = np.array([[1/3, 2/3],\n",
    "                  [3/4, 1/4]])\n",
    "rw = RandomWalk(states, trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that the chain starts in state 0 at time n = 0, what is the probability that it is in state 1 at time n = 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49537037 0.50462963]\n",
      " [0.56770833 0.43229167]]\n",
      "ANSWER: 0.5046296296296295\n"
     ]
    }
   ],
   "source": [
    "third_step_trans = rw.trans_power(3)\n",
    "print(third_step_trans)\n",
    "print(\"ANSWER:\", third_step_trans[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise1_3\n",
    "\n",
    "Consider a Markov chain with state space \\{1, 2, 3\\} and transition matrix\n",
    "\n",
    "$$\n",
    "P =\n",
    "\\left(\\begin{array}{cc} \n",
    "0.4 & 0.2 & 0.4\\\\\n",
    "0.6 & 0 & 0.4 \\\\\n",
    "0.2 & 0.5 & 0.3\n",
    "\\end{array}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [1, 2, 3]\n",
    "trans = np.array([[0.4, 0.2, 0.4],\n",
    "                  [0.6,  0 , 0.4],\n",
    "                  [0.2, 0.5, 0.3]])\n",
    "rw = RandomWalk(states, trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is the probability in the long run that the chain is in state 1?\n",
    "Solve this problem two different ways:\n",
    "\n",
    "1) by raising the matrix to a high power:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37878788, 0.25757576, 0.36363636],\n",
       "       [0.37878788, 0.25757576, 0.36363636],\n",
       "       [0.37878788, 0.25757576, 0.36363636]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw.trans_power(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) by directly computing the invariant probability vector as a left eigenvector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37878788, 0.25757576, 0.36363636])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw.final_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise1_4\n",
    "\n",
    "Do the same with\n",
    "\n",
    "$$\n",
    "P =\n",
    "\\left(\\begin{array}{cc} \n",
    "0.2 & 0.4 & 0.4\\\\\n",
    "0.1 & 0.5 & 0.4 \\\\\n",
    "0.6 & 0.3 & 0.1\n",
    "\\end{array}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [1, 2, 3]\n",
    "trans = np.array([[0.2, 0.4, 0.4],\n",
    "                  [0.1, 0.5, 0.4],\n",
    "                  [0.6, 0.3, 0.1]])\n",
    "rw = RandomWalk(states, trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) by raising the matrix to a high power:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28205128, 0.41025641, 0.30769231],\n",
       "       [0.28205128, 0.41025641, 0.30769231],\n",
       "       [0.28205128, 0.41025641, 0.30769231]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw.trans_power(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) by directly computing the invariant probability vector as a left eigenvector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28205128, 0.41025641, 0.30769231])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw.final_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise1_5\n",
    "\n",
    "Consider the Markov chain with state space $ S = \\{0, ..., 5\\} $ and transition matrix:\n",
    "\n",
    "$$\n",
    "P =\n",
    "\\left(\\begin{array}{cc} \n",
    "0.5 & 0.5 & 0 & 0 & 0 & 0\\\\\n",
    "0.3 & 0.7 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0.1 & 0 & 0 & 0.9 \\\\\n",
    "0.25 & 0.25 & 0 & 0 & 0.25 & 0.25 \\\\\n",
    "0 & 0 & 0.7 & 0 & 0.3 & 0 \\\\\n",
    "0 & 0.2 & 0 & 0.2 & 0.2 & 0.4 \\\\\n",
    "\\end{array}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = list(range(6))\n",
    "trans = np.array([[0.5, 0.5, 0  , 0  , 0  , 0  ],\n",
    "                  [0.3, 0.7, 0  , 0  , 0  , 0  ],\n",
    "                  [0  , 0  , 0.1, 0  , 0  , 0.9],\n",
    "                  [.25, .25, 0  , 0  , .25, .25],\n",
    "                  [0  , 0  , 0.7, 0  , 0.3, 0  ],\n",
    "                  [0  , 0.2, 0  , 0.2, 0.2, 0.4]])\n",
    "rw = RandomWalk(states, trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the communication classes? Which ones are recurrent and which are transient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'recurrent': ([0, 1],\n  array([[0.5, 0.5],\n         [0.3, 0.7]])),\n 'transient': ([2, 3, 4, 5],\n  array([[0.1 , 0.  , 0.  , 0.9 ],\n         [0.  , 0.  , 0.25, 0.25],\n         [0.7 , 0.  , 0.3 , 0.  ],\n         [0.  , 0.2 , 0.2 , 0.4 ]]))}"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "rw.get_typeof_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the system starts in state 0. What is the probability that it will be in state 0 at some large time? Answer the same question assuming the system starts in state 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.37499999999998634\n8.081964030507363e-71\n"
    }
   ],
   "source": [
    "p_1000 = rw.trans_power(1000)\n",
    "print(p_1000[0, 0])\n",
    "print(p_1000[5, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise1_8\n",
    "\n",
    "Consider simple random walk on the graph below. (Recall that simple random walk on a graph is the Markov chain which at each time moves to an adjacent vertex, each adjacent vertex having the same probability):\n",
    "\n",
    "$$\n",
    "P =\n",
    "\\left(\\begin{array}{cc} \n",
    "0 & 1/3 & 1/3 & 1/3 & 0 \\\\\n",
    "1/3 & 0 & 1/3 & 0 & 1/3 \\\\\n",
    "1/2 & 1/2 & 0 & 0 & 0 \\\\\n",
    "1/2 & 0 & 0 & 0 & 1/2 \\\\\n",
    "0 & 1/2 & 0 & 1/2 & 0 \\\\\n",
    "\\end{array}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "states = list(range(5))\n",
    "trans = np.array([[0, 1/3, 1/3, 1/3,   0],\n",
    "                  [1/3, 0, 1/3,   0, 1/3],\n",
    "                  [1/2, 1/2, 0,   0,   0],\n",
    "                  [1/2,   0, 0,   0, 1/2],\n",
    "                  [0  , 1/2, 0, 1/2,   0]])\n",
    "rw = RandomWalk(states, trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) In the long run, what function of time is spent in vertex A?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.2500000000000003\n"
    }
   ],
   "source": [
    "final_dist = rw.final_dist()\n",
    "print(final_dist[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimal_Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise4_1\n",
    "Consider a simple random walk ($p = 1/2$) with absorbing boundaries on $\\{0,1,2,...,10\\}$. Suppose the fallowing payoff function is given:\n",
    "\n",
    "$$\n",
    "[0,2,4,3,10,0,6,4,3,3,0]\n",
    "$$\n",
    "Find the optimal stopping rule and give the expected payoff starting at each site.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "states = list(range(11))\n",
    "trans = np.array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                  [.5,0,.5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                  [0, .5,0,.5, 0, 0, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, .5,0,.5, 0, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, .5,0,.5, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, .5,0,.5, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, .5,0,.5, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, .5,0,.5, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, .5,0,.5, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, .5,0,.5],\n",
    "                  [0, 0, 0, 0, 0, 0, 0 ,0, 0, 0, 1]])\n",
    "rw = RandomWalk(states, trans, payoff=[0,2,4,3,10,0,6,4,3,3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'continue': [1, 2, 3, 5, 6, 7, 8], 'stop': [0, 4, 9, 10]}\n"
    }
   ],
   "source": [
    "best_policy = rw.best_policy()\n",
    "print(best_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which implies that it's better to stop in $[0, 4, 9, 10]$ and continue otherwise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}